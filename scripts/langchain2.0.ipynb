{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain_community.graphs import Neo4jGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhruvchandel/opt/anaconda3/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 0.2.0. Use HuggingFaceEndpoint instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import HuggingFaceHub\n",
    "\n",
    "repo_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "\n",
    "llm_new = HuggingFaceHub(\n",
    "    repo_id=repo_id,\n",
    "    task=\"text-generation\",\n",
    "    huggingfacehub_api_token = \"<your-api-key>\",\n",
    "    model_kwargs={\n",
    "        \"max_new_tokens\": 100,\n",
    "        \"top_k\": 10,\n",
    "        \"top_p\": 0.95,\n",
    "        \"typical_p\": 0.95,\n",
    "        \"temperature\": 0.7,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph(\n",
    "    url=\"neo4j+s://46a80122.databases.neo4j.io:7687\",\n",
    "    username=\"<user>\", \n",
    "    password=\"<pass>\",\n",
    "    refresh_schema=True, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties are the following:\n",
      "Article {id: INTEGER, name: STRING, url: STRING, creativeWorkType: STRING, metadata_url: STRING},Code {id: INTEGER, name: STRING, url: STRING, creativeWorkType: STRING, metadata_url: STRING},Dataset {id: INTEGER, name: STRING, url: STRING, creativeWorkType: STRING, metadata_url: STRING},SoftwareApplication {id: INTEGER, name: STRING, url: STRING, creativeWorkType: STRING, metadata_url: STRING}\n",
      "Relationship properties are the following:\n",
      "\n",
      "The relationships are the following:\n",
      "(:Article)-[:uses]->(:Dataset),(:Article)-[:provides]->(:Code),(:Article)-[:provides]->(:SoftwareApplication),(:Article)-[:cites]->(:Article)\n"
     ]
    }
   ],
   "source": [
    "schema=graph.schema\n",
    "print(graph.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "\n",
    "CYPHER_GENERATION_TEMPLATE = \"\"\"Task:Generate Cypher statement to query a graph database.\n",
    "Instructions:\n",
    "Use only the provided relationship types and properties in the schema.\n",
    "Do not use any other relationship types or properties that are not provided.\n",
    "Schema:\n",
    "{schema}\n",
    "Note: Do not include any explanations or apologies in your responses.\n",
    "Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
    "Do not include any text except the generated Cypher statement.\n",
    "Examples: Here are a few examples of generated Cypher statements for particular questions:\n",
    "# How many published paper are there?\n",
    "MATCH (a:Article)\n",
    "RETURN COUNT(a) AS numberOfArticles\n",
    "\n",
    "\n",
    "The question is:\n",
    "{question}\"\"\"\n",
    "\n",
    "CYPHER_GENERATION_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"schema\", \"question\"], template=CYPHER_GENERATION_TEMPLATE\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How many published papers are there?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = CYPHER_GENERATION_PROMPT.format(schema=schema, question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task:Generate Cypher statement to query a graph database.\\nInstructions:\\nUse only the provided relationship types and properties in the schema.\\nDo not use any other relationship types or properties that are not provided.\\nSchema:\\nNode properties are the following:\\nArticle {id: INTEGER, name: STRING, url: STRING, creativeWorkType: STRING, metadata_url: STRING},Code {id: INTEGER, name: STRING, url: STRING, creativeWorkType: STRING, metadata_url: STRING},Dataset {id: INTEGER, name: STRING, url: STRING, creativeWorkType: STRING, metadata_url: STRING},SoftwareApplication {id: INTEGER, name: STRING, url: STRING, creativeWorkType: STRING, metadata_url: STRING}\\nRelationship properties are the following:\\n\\nThe relationships are the following:\\n(:Article)-[:uses]->(:Dataset),(:Article)-[:provides]->(:Code),(:Article)-[:provides]->(:SoftwareApplication),(:Article)-[:cites]->(:Article)\\nNote: Do not include any explanations or apologies in your responses.\\nDo not respond to any questions that might ask anything else than for you to construct a Cypher statement.\\nDo not include any text except the generated Cypher statement.\\nExamples: Here are a few examples of generated Cypher statements for particular questions:\\n# How many published paper are there?\\nMATCH (a:Article)\\nRETURN COUNT(a) AS numberOfArticles\\n\\n\\nThe question is:\\nHow many published papers are there?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm_new.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cypher_query(output):\n",
    "    # Split the output into lines\n",
    "    lines = output.strip().split('\\n')\n",
    "    \n",
    "    # Find the index of the last line containing the Cypher query\n",
    "    for i in range(len(lines) - 1, -1, -1):  # Iterate in reverse\n",
    "        if lines[i].strip().startswith('MATCH'):\n",
    "            # Join all lines starting from this index to the end\n",
    "            return '\\n'.join(lines[i:])\n",
    "    \n",
    "    return None  # Return None if no query found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_query = extract_cypher_query(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATCH (a:Article)\n",
      "RETURN COUNT(a) AS numberOfArticles\n"
     ]
    }
   ],
   "source": [
    "print(cypher_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_cypher_query(graph, cypher_query):\n",
    "    with graph._driver.session() as session:  # Use the session from the existing graph object\n",
    "        result = session.run(cypher_query)\n",
    "        return [record.data() for record in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'numberOfArticles': 30}]\n"
     ]
    }
   ],
   "source": [
    "print(execute_cypher_query(graph, cypher_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_natural_language(llm, result, question):\n",
    "    # Construct a prompt for the LLM\n",
    "    prompt = f\"Transform the following result into a natural language statement:\\n\\nResult: {result}, where the user question was : {question} \\n\\nOutput:\"\n",
    "    \n",
    "    # Call the LLM to generate the response\n",
    "    response = llm_new(prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhruvchandel/opt/anaconda3/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform the following result into a natural language statement:\n",
      "\n",
      "Result: [{'numberOfArticles': 30}], where the user question was : How many published papers are there? \n",
      "\n",
      "Output: There are 30 published papers.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "natural_language_response = transform_to_natural_language(llm_new, execute_cypher_query(graph, cypher_query), question)\n",
    "print(natural_language_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
